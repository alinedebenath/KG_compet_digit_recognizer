{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1st Kaggle competition : digit recognizer</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from time import time\n",
    "from tensorflow.python.keras.utils import np_utils, to_categorical\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.keras.constraints import maxnorm\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c15077be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.label.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=(data.drop(columns='label')).values\n",
    "labeled_data_num=(data.label).values\n",
    "labeled_data=to_categorical(labeled_data_num)\n",
    "train_data0 = train_data.reshape(train_data.shape[0], 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\matplotlib\\text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,13))\n",
    "for i in range(5, 9):\n",
    "    plt.subplot(450 + (i+1))\n",
    "    plt.imshow(train_data0[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(labeled_data_num[i])\n",
    "    plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns='label'), data.label, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 695.26 seconds for 18 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.857 (std: 0.003)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 9}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.853 (std: 0.005)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.827 (std: 0.007)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=data.drop(columns='label')\n",
    "y=data.label\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [1, 3, 5, 6],\n",
    "              \"max_features\": [2, 3, 5, 9],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639285714285715"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc  = RandomForestClassifier(n_estimators = 300,criterion= 'gini', max_depth= 5, max_features=9)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-1af8f57deeb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X=data.drop(columns='label')\n",
    "y=data.label\n",
    "\n",
    "xgboost = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"eta\": [0.01, 0.2],\n",
    "              \"max_depth\": [3,6,9]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xgboost, param_grid=param_grid, cv=10, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332142857142857"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBClassifier(objective='multi:softmax', num_class=10, \n",
    "        n_jobs=-1,booster=\"gbtree\",tree_method = \"hist\",\n",
    "        grow_policy = \"depthwise\")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "labels = train.label.values.astype('int32')\n",
    "X_train = (train.drop(columns='label').values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "y_test=(pd.read_csv('test.csv').values).astype('int32')\n",
    "# convert list of labels to binary class matrix\n",
    "y_train = np_utils.to_categorical(labels) \n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "X=(train.drop(columns='label').values).astype('float32')\n",
    "y=train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.975571 using {'batch_size': 80, 'epochs': 100}\n",
      "0.964190 (0.000468) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.958238 (0.005936) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.959738 (0.003773) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.959690 (0.000738) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.971667 (0.002419) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.968071 (0.003529) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.967381 (0.002014) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.970476 (0.003109) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.973143 (0.003031) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.966333 (0.002447) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.973738 (0.002171) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.974524 (0.001685) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.966024 (0.002037) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.972810 (0.002663) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.975571 (0.000440) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.964119 (0.003253) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.972548 (0.001713) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.974738 (0.001480) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for epochs and batch size\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='lecun_uniform',\n",
    "                    kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softsign'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best optimizer: 0.974024 using {'optimizer': 'Adadelta'}\n",
      "0.947262 (0.001424) with: {'optimizer': 'SGD'}\n",
      "0.973000 (0.001012) with: {'optimizer': 'RMSprop'}\n",
      "0.965548 (0.001770) with: {'optimizer': 'Adagrad'}\n",
      "0.974024 (0.001957) with: {'optimizer': 'Adadelta'}\n",
      "0.973952 (0.000414) with: {'optimizer': 'Adam'}\n",
      "0.972833 (0.001557) with: {'optimizer': 'Adamax'}\n",
      "0.968881 (0.000915) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for optimizer\n",
    "def create_model(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='lecun_uniform',\n",
    "                    kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softsign'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,kernel_initializer='lecun_uniform',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best optimizer: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best init mode 1: 0.908667 using {'init_mode': 'he_normal'}\n",
      "0.820929 (0.008248) with: {'init_mode': 'uniform'}\n",
      "0.906024 (0.000288) with: {'init_mode': 'lecun_uniform'}\n",
      "0.904310 (0.001201) with: {'init_mode': 'normal'}\n",
      "0.111524 (0.001483) with: {'init_mode': 'zero'}\n",
      "0.907214 (0.001853) with: {'init_mode': 'glorot_normal'}\n",
      "0.905024 (0.002491) with: {'init_mode': 'glorot_uniform'}\n",
      "0.908667 (0.000945) with: {'init_mode': 'he_normal'}\n",
      "0.906881 (0.000453) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for init mode\n",
    "def create_model(init_mode='uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer=init_mode,\n",
    "                    kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softsign'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=80, batch_size=100, verbose=0)\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best init mode 1: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best init mode 2: 0.907452 using {'init_mode': 'uniform'}\n",
      "0.907452 (0.003243) with: {'init_mode': 'uniform'}\n",
      "0.904286 (0.001069) with: {'init_mode': 'lecun_uniform'}\n",
      "0.904119 (0.003587) with: {'init_mode': 'normal'}\n",
      "0.906333 (0.002216) with: {'init_mode': 'zero'}\n",
      "0.906024 (0.002616) with: {'init_mode': 'glorot_normal'}\n",
      "0.905310 (0.002005) with: {'init_mode': 'glorot_uniform'}\n",
      "0.905452 (0.001874) with: {'init_mode': 'he_normal'}\n",
      "0.905262 (0.000676) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for init mode\n",
    "def create_model(init_mode='uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='he_uniform',\n",
    "\t                kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softsign'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=80, batch_size=100, verbose=0)\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best init mode 2: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 1: 0.977262 using {'activation': 'softplus'}\n",
      "0.953381 (0.001058) with: {'activation': 'softmax'}\n",
      "0.977262 (0.001024) with: {'activation': 'softplus'}\n",
      "0.974929 (0.000974) with: {'activation': 'softsign'}\n",
      "0.976667 (0.000725) with: {'activation': 'relu'}\n",
      "0.976000 (0.001147) with: {'activation': 'tanh'}\n",
      "0.975333 (0.000618) with: {'activation': 'sigmoid'}\n",
      "0.976429 (0.001010) with: {'activation': 'hard_sigmoid'}\n",
      "0.974286 (0.000408) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',\n",
    "                kernel_constraint=maxnorm(2), activation=activation))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128, kernel_initializer='he_uniform',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=80, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best activation 1: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 2: 0.966690 using {'activation': 'softplus'}\n",
      "0.952571 (0.003156) with: {'activation': 'softmax'}\n",
      "0.966690 (0.002337) with: {'activation': 'softplus'}\n",
      "0.961976 (0.002402) with: {'activation': 'softsign'}\n",
      "0.966476 (0.001837) with: {'activation': 'relu'}\n",
      "0.963952 (0.002380) with: {'activation': 'tanh'}\n",
      "0.962738 (0.000930) with: {'activation': 'sigmoid'}\n",
      "0.963095 (0.002140) with: {'activation': 'hard_sigmoid'}\n",
      "0.960381 (0.001268) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='he_uniform',kernel_constraint=maxnorm(1)\n",
    "                    ,activation='softsign'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,activation=activation,kernel_initializer='he_uniform',kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(nb_classes,activation='softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=80, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best activation 2: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 3: 0.967619 using {'activation': 'sigmoid'}\n",
      "0.964357 (0.004748) with: {'activation': 'softmax'}\n",
      "0.966381 (0.000663) with: {'activation': 'softplus'}\n",
      "0.096357 (0.002122) with: {'activation': 'softsign'}\n",
      "0.098381 (0.001807) with: {'activation': 'relu'}\n",
      "0.138310 (0.036440) with: {'activation': 'tanh'}\n",
      "0.967619 (0.001584) with: {'activation': 'sigmoid'}\n",
      "0.378286 (0.345053) with: {'activation': 'hard_sigmoid'}\n",
      "0.099571 (0.002241) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform',\n",
    "                    activation='softsign',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,activation='softplus',kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(nb_classes,activation=activation))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=80, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best activation 3: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neurons: 0.972595 using {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.971357 (0.000707) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.972595 (0.001411) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.971833 (0.001257) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.972214 (0.001229) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.971071 (0.000917) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.970643 (0.000955) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.970833 (0.000893) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.970262 (0.000738) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.967786 (0.000309) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.966929 (0.000911) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.967357 (0.002291) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.966167 (0.001196) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.962071 (0.001287) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.961714 (0.001113) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.962310 (0.000584) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.961048 (0.000937) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.382048 (0.399786) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.098381 (0.001807) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.380690 (0.398930) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.098381 (0.001807) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform',\n",
    "                    activation='softsign',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,activation='relu',kernel_constraint=maxnorm(weight_constraint)))\n",
    "\tmodel.add(Dropout(dropout_rate))\n",
    "\tmodel.add(Dense(nb_classes,activation='softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 4, 5]\n",
    "dropout_rate = [0.1, 0.3,  0.5, 0.7, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best neurons: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/80\n",
      " - 12s - loss: 0.6361 - acc: 0.8184 - val_loss: 0.2976 - val_acc: 0.9140\n",
      "Epoch 2/80\n",
      " - 6s - loss: 0.3262 - acc: 0.9036 - val_loss: 0.2359 - val_acc: 0.9300\n",
      "Epoch 3/80\n",
      " - 6s - loss: 0.2713 - acc: 0.9200 - val_loss: 0.2001 - val_acc: 0.9381\n",
      "Epoch 4/80\n",
      " - 6s - loss: 0.2376 - acc: 0.9308 - val_loss: 0.1801 - val_acc: 0.9471\n",
      "Epoch 5/80\n",
      " - 7s - loss: 0.2175 - acc: 0.9343 - val_loss: 0.1621 - val_acc: 0.9500\n",
      "Epoch 6/80\n",
      " - 6s - loss: 0.1958 - acc: 0.9425 - val_loss: 0.1593 - val_acc: 0.9521\n",
      "Epoch 7/80\n",
      " - 6s - loss: 0.1811 - acc: 0.9439 - val_loss: 0.1468 - val_acc: 0.9550\n",
      "Epoch 8/80\n",
      " - 6s - loss: 0.1694 - acc: 0.9484 - val_loss: 0.1383 - val_acc: 0.9571\n",
      "Epoch 9/80\n",
      " - 5s - loss: 0.1592 - acc: 0.9522 - val_loss: 0.1352 - val_acc: 0.9571\n",
      "Epoch 10/80\n",
      " - 6s - loss: 0.1509 - acc: 0.9535 - val_loss: 0.1380 - val_acc: 0.9552\n",
      "Epoch 11/80\n",
      " - 6s - loss: 0.1456 - acc: 0.9547 - val_loss: 0.1198 - val_acc: 0.9612\n",
      "Epoch 12/80\n",
      " - 6s - loss: 0.1395 - acc: 0.9573 - val_loss: 0.1152 - val_acc: 0.9655\n",
      "Epoch 13/80\n",
      " - 6s - loss: 0.1324 - acc: 0.9594 - val_loss: 0.1195 - val_acc: 0.9638\n",
      "Epoch 14/80\n",
      " - 6s - loss: 0.1305 - acc: 0.9595 - val_loss: 0.1110 - val_acc: 0.9626\n",
      "Epoch 15/80\n",
      " - 5s - loss: 0.1248 - acc: 0.9618 - val_loss: 0.1123 - val_acc: 0.9629\n",
      "Epoch 16/80\n",
      " - 5s - loss: 0.1214 - acc: 0.9629 - val_loss: 0.1081 - val_acc: 0.9655\n",
      "Epoch 17/80\n",
      " - 5s - loss: 0.1166 - acc: 0.9638 - val_loss: 0.1033 - val_acc: 0.9664\n",
      "Epoch 18/80\n",
      " - 5s - loss: 0.1138 - acc: 0.9650 - val_loss: 0.1051 - val_acc: 0.9660\n",
      "Epoch 19/80\n",
      " - 6s - loss: 0.1105 - acc: 0.9665 - val_loss: 0.1073 - val_acc: 0.9648\n",
      "Epoch 20/80\n",
      " - 5s - loss: 0.1103 - acc: 0.9660 - val_loss: 0.1001 - val_acc: 0.9674\n",
      "Epoch 21/80\n",
      " - 7s - loss: 0.1063 - acc: 0.9671 - val_loss: 0.1049 - val_acc: 0.9664\n",
      "Epoch 22/80\n",
      " - 6s - loss: 0.1054 - acc: 0.9667 - val_loss: 0.0978 - val_acc: 0.9662\n",
      "Epoch 23/80\n",
      " - 5s - loss: 0.1013 - acc: 0.9685 - val_loss: 0.0997 - val_acc: 0.9688\n",
      "Epoch 24/80\n",
      " - 6s - loss: 0.0979 - acc: 0.9697 - val_loss: 0.0989 - val_acc: 0.9688\n",
      "Epoch 25/80\n",
      " - 7s - loss: 0.0966 - acc: 0.9698 - val_loss: 0.1001 - val_acc: 0.9686\n",
      "Epoch 26/80\n",
      " - 6s - loss: 0.0941 - acc: 0.9704 - val_loss: 0.0996 - val_acc: 0.9681\n",
      "Epoch 27/80\n",
      " - 6s - loss: 0.0942 - acc: 0.9713 - val_loss: 0.0986 - val_acc: 0.9688\n",
      "Epoch 28/80\n",
      " - 6s - loss: 0.0923 - acc: 0.9710 - val_loss: 0.1003 - val_acc: 0.9671\n",
      "Epoch 29/80\n",
      " - 6s - loss: 0.0942 - acc: 0.9709 - val_loss: 0.0917 - val_acc: 0.9698\n",
      "Epoch 30/80\n",
      " - 6s - loss: 0.0882 - acc: 0.9726 - val_loss: 0.0891 - val_acc: 0.9700\n",
      "Epoch 31/80\n",
      " - 6s - loss: 0.0877 - acc: 0.9721 - val_loss: 0.0926 - val_acc: 0.9698\n",
      "Epoch 32/80\n",
      " - 6s - loss: 0.0844 - acc: 0.9735 - val_loss: 0.0918 - val_acc: 0.9705\n",
      "Epoch 33/80\n",
      " - 5s - loss: 0.0859 - acc: 0.9731 - val_loss: 0.0907 - val_acc: 0.9698\n",
      "Epoch 34/80\n",
      " - 5s - loss: 0.0844 - acc: 0.9738 - val_loss: 0.0903 - val_acc: 0.9702\n",
      "Epoch 35/80\n",
      " - 5s - loss: 0.0831 - acc: 0.9734 - val_loss: 0.0921 - val_acc: 0.9714\n",
      "Epoch 36/80\n",
      " - 5s - loss: 0.0828 - acc: 0.9740 - val_loss: 0.0900 - val_acc: 0.9719\n",
      "Epoch 37/80\n",
      " - 5s - loss: 0.0795 - acc: 0.9745 - val_loss: 0.0894 - val_acc: 0.9698\n",
      "Epoch 38/80\n",
      " - 5s - loss: 0.0806 - acc: 0.9746 - val_loss: 0.0849 - val_acc: 0.9738\n",
      "Epoch 39/80\n",
      " - 5s - loss: 0.0774 - acc: 0.9758 - val_loss: 0.0911 - val_acc: 0.9686\n",
      "Epoch 40/80\n",
      " - 5s - loss: 0.0763 - acc: 0.9755 - val_loss: 0.0867 - val_acc: 0.9729\n",
      "Epoch 41/80\n",
      " - 5s - loss: 0.0772 - acc: 0.9751 - val_loss: 0.0923 - val_acc: 0.9717\n",
      "Epoch 42/80\n",
      " - 5s - loss: 0.0769 - acc: 0.9757 - val_loss: 0.0827 - val_acc: 0.9724\n",
      "Epoch 43/80\n",
      " - 6s - loss: 0.0739 - acc: 0.9757 - val_loss: 0.0841 - val_acc: 0.9731\n",
      "Epoch 44/80\n",
      " - 6s - loss: 0.0750 - acc: 0.9762 - val_loss: 0.0858 - val_acc: 0.9721\n",
      "Epoch 45/80\n",
      " - 5s - loss: 0.0721 - acc: 0.9769 - val_loss: 0.0880 - val_acc: 0.9731\n",
      "Epoch 46/80\n",
      " - 6s - loss: 0.0730 - acc: 0.9775 - val_loss: 0.0871 - val_acc: 0.9721\n",
      "Epoch 47/80\n",
      " - 6s - loss: 0.0711 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 0.9733\n",
      "Epoch 48/80\n",
      " - 6s - loss: 0.0735 - acc: 0.9763 - val_loss: 0.0887 - val_acc: 0.9729\n",
      "Epoch 49/80\n",
      " - 5s - loss: 0.0688 - acc: 0.9773 - val_loss: 0.0857 - val_acc: 0.9726\n",
      "Epoch 50/80\n",
      " - 6s - loss: 0.0713 - acc: 0.9771 - val_loss: 0.0834 - val_acc: 0.9731\n",
      "Epoch 51/80\n",
      " - 7s - loss: 0.0656 - acc: 0.9789 - val_loss: 0.0885 - val_acc: 0.9717\n",
      "Epoch 52/80\n",
      " - 7s - loss: 0.0663 - acc: 0.9797 - val_loss: 0.0941 - val_acc: 0.9719\n",
      "Epoch 53/80\n",
      " - 6s - loss: 0.0685 - acc: 0.9784 - val_loss: 0.0870 - val_acc: 0.9745\n",
      "Epoch 54/80\n",
      " - 6s - loss: 0.0675 - acc: 0.9776 - val_loss: 0.0890 - val_acc: 0.9745\n",
      "Epoch 55/80\n",
      " - 5s - loss: 0.0673 - acc: 0.9784 - val_loss: 0.0851 - val_acc: 0.9752\n",
      "Epoch 56/80\n",
      " - 5s - loss: 0.0661 - acc: 0.9785 - val_loss: 0.0817 - val_acc: 0.9750\n",
      "Epoch 57/80\n",
      " - 5s - loss: 0.0659 - acc: 0.9788 - val_loss: 0.0844 - val_acc: 0.9733\n",
      "Epoch 58/80\n",
      " - 5s - loss: 0.0621 - acc: 0.9792 - val_loss: 0.0860 - val_acc: 0.9729\n",
      "Epoch 59/80\n",
      " - 5s - loss: 0.0646 - acc: 0.9789 - val_loss: 0.0886 - val_acc: 0.9733\n",
      "Epoch 60/80\n",
      " - 5s - loss: 0.0642 - acc: 0.9794 - val_loss: 0.0830 - val_acc: 0.9745\n",
      "Epoch 61/80\n",
      " - 6s - loss: 0.0649 - acc: 0.9792 - val_loss: 0.0832 - val_acc: 0.9724\n",
      "Epoch 62/80\n",
      " - 5s - loss: 0.0657 - acc: 0.9784 - val_loss: 0.0796 - val_acc: 0.9769\n",
      "Epoch 63/80\n",
      " - 5s - loss: 0.0617 - acc: 0.9802 - val_loss: 0.0829 - val_acc: 0.9736\n",
      "Epoch 64/80\n",
      " - 6s - loss: 0.0625 - acc: 0.9794 - val_loss: 0.0857 - val_acc: 0.9752\n",
      "Epoch 65/80\n",
      " - 5s - loss: 0.0628 - acc: 0.9803 - val_loss: 0.0856 - val_acc: 0.9755\n",
      "Epoch 66/80\n",
      " - 5s - loss: 0.0604 - acc: 0.9808 - val_loss: 0.0854 - val_acc: 0.9733\n",
      "Epoch 67/80\n",
      " - 5s - loss: 0.0595 - acc: 0.9802 - val_loss: 0.0825 - val_acc: 0.9745\n",
      "Epoch 68/80\n",
      " - 6s - loss: 0.0639 - acc: 0.9792 - val_loss: 0.0876 - val_acc: 0.9733\n",
      "Epoch 69/80\n",
      " - 5s - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0817 - val_acc: 0.9750\n",
      "Epoch 70/80\n",
      " - 7s - loss: 0.0601 - acc: 0.9803 - val_loss: 0.0823 - val_acc: 0.9755\n",
      "Epoch 71/80\n",
      " - 6s - loss: 0.0582 - acc: 0.9816 - val_loss: 0.0854 - val_acc: 0.9738\n",
      "Epoch 72/80\n",
      " - 6s - loss: 0.0587 - acc: 0.9815 - val_loss: 0.0819 - val_acc: 0.9738\n",
      "Epoch 73/80\n",
      " - 6s - loss: 0.0571 - acc: 0.9810 - val_loss: 0.0808 - val_acc: 0.9762\n",
      "Epoch 74/80\n",
      " - 5s - loss: 0.0592 - acc: 0.9798 - val_loss: 0.0802 - val_acc: 0.9752\n",
      "Epoch 75/80\n",
      " - 5s - loss: 0.0566 - acc: 0.9816 - val_loss: 0.0790 - val_acc: 0.9757\n",
      "Epoch 76/80\n",
      " - 5s - loss: 0.0535 - acc: 0.9824 - val_loss: 0.0848 - val_acc: 0.9726\n",
      "Epoch 77/80\n",
      " - 5s - loss: 0.0587 - acc: 0.9813 - val_loss: 0.0828 - val_acc: 0.9731\n",
      "Epoch 78/80\n",
      " - 5s - loss: 0.0565 - acc: 0.9815 - val_loss: 0.0838 - val_acc: 0.9743\n",
      "Epoch 79/80\n",
      " - 5s - loss: 0.0569 - acc: 0.9809 - val_loss: 0.0759 - val_acc: 0.9752\n",
      "Epoch 80/80\n",
      " - 6s - loss: 0.0561 - acc: 0.9823 - val_loss: 0.0789 - val_acc: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26c0b18be80>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BEST\n",
    "train = pd.read_csv('train.csv')\n",
    "labels = train.label.values.astype('int32')\n",
    "X_train = (train.drop(columns='label').values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "\n",
    "# convert list of labels to binary class matrix\n",
    "y_train = np_utils.to_categorical(labels) \n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',kernel_constraint=maxnorm(2)))\n",
    "model.add(Activation('softsign'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, kernel_initializer='he_uniform',kernel_constraint=maxnorm(1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softplus'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=100, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/80\n",
      " - 6s - loss: 0.6349 - acc: 0.8170 - val_loss: 0.2955 - val_acc: 0.9143\n",
      "Epoch 2/80\n",
      " - 4s - loss: 0.3373 - acc: 0.9001 - val_loss: 0.2358 - val_acc: 0.9305\n",
      "Epoch 3/80\n",
      " - 4s - loss: 0.2857 - acc: 0.9169 - val_loss: 0.2121 - val_acc: 0.9360\n",
      "Epoch 4/80\n",
      " - 4s - loss: 0.2480 - acc: 0.9263 - val_loss: 0.1899 - val_acc: 0.9400\n",
      "Epoch 5/80\n",
      " - 4s - loss: 0.2208 - acc: 0.9344 - val_loss: 0.1743 - val_acc: 0.9440\n",
      "Epoch 6/80\n",
      " - 4s - loss: 0.2039 - acc: 0.9390 - val_loss: 0.1663 - val_acc: 0.9464\n",
      "Epoch 7/80\n",
      " - 5s - loss: 0.1867 - acc: 0.9454 - val_loss: 0.1533 - val_acc: 0.9510\n",
      "Epoch 8/80\n",
      " - 4s - loss: 0.1750 - acc: 0.9481 - val_loss: 0.1415 - val_acc: 0.9548\n",
      "Epoch 9/80\n",
      " - 4s - loss: 0.1658 - acc: 0.9500 - val_loss: 0.1350 - val_acc: 0.9581\n",
      "Epoch 10/80\n",
      " - 4s - loss: 0.1586 - acc: 0.9528 - val_loss: 0.1351 - val_acc: 0.9586\n",
      "Epoch 11/80\n",
      " - 4s - loss: 0.1512 - acc: 0.9547 - val_loss: 0.1293 - val_acc: 0.9576\n",
      "Epoch 12/80\n",
      " - 4s - loss: 0.1456 - acc: 0.9562 - val_loss: 0.1263 - val_acc: 0.9598\n",
      "Epoch 13/80\n",
      " - 4s - loss: 0.1368 - acc: 0.9579 - val_loss: 0.1220 - val_acc: 0.9612\n",
      "Epoch 14/80\n",
      " - 4s - loss: 0.1313 - acc: 0.9601 - val_loss: 0.1180 - val_acc: 0.9621\n",
      "Epoch 15/80\n",
      " - 5s - loss: 0.1287 - acc: 0.9611 - val_loss: 0.1143 - val_acc: 0.9619\n",
      "Epoch 16/80\n",
      " - 4s - loss: 0.1212 - acc: 0.9633 - val_loss: 0.1123 - val_acc: 0.9645\n",
      "Epoch 17/80\n",
      " - 4s - loss: 0.1198 - acc: 0.9628 - val_loss: 0.1109 - val_acc: 0.9629\n",
      "Epoch 18/80\n",
      " - 4s - loss: 0.1196 - acc: 0.9627 - val_loss: 0.1114 - val_acc: 0.9643\n",
      "Epoch 19/80\n",
      " - 4s - loss: 0.1137 - acc: 0.9655 - val_loss: 0.1067 - val_acc: 0.9643\n",
      "Epoch 20/80\n",
      " - 4s - loss: 0.1154 - acc: 0.9643 - val_loss: 0.1080 - val_acc: 0.9657\n",
      "Epoch 21/80\n",
      " - 4s - loss: 0.1101 - acc: 0.9657 - val_loss: 0.1038 - val_acc: 0.9655\n",
      "Epoch 22/80\n",
      " - 5s - loss: 0.1050 - acc: 0.9671 - val_loss: 0.1094 - val_acc: 0.9631\n",
      "Epoch 23/80\n",
      " - 4s - loss: 0.1058 - acc: 0.9672 - val_loss: 0.1067 - val_acc: 0.9655\n",
      "Epoch 24/80\n",
      " - 4s - loss: 0.1064 - acc: 0.9672 - val_loss: 0.0964 - val_acc: 0.9667\n",
      "Epoch 25/80\n",
      " - 4s - loss: 0.1010 - acc: 0.9692 - val_loss: 0.1006 - val_acc: 0.9657\n",
      "Epoch 26/80\n",
      " - 4s - loss: 0.0987 - acc: 0.9696 - val_loss: 0.0995 - val_acc: 0.9660\n",
      "Epoch 27/80\n",
      " - 4s - loss: 0.0971 - acc: 0.9695 - val_loss: 0.0974 - val_acc: 0.9676\n",
      "Epoch 28/80\n",
      " - 4s - loss: 0.0961 - acc: 0.9699 - val_loss: 0.0932 - val_acc: 0.9686\n",
      "Epoch 29/80\n",
      " - 4s - loss: 0.0917 - acc: 0.9712 - val_loss: 0.1021 - val_acc: 0.9657\n",
      "Epoch 30/80\n",
      " - 4s - loss: 0.0916 - acc: 0.9720 - val_loss: 0.0931 - val_acc: 0.9686\n",
      "Epoch 31/80\n",
      " - 4s - loss: 0.0899 - acc: 0.9723 - val_loss: 0.0965 - val_acc: 0.9676\n",
      "Epoch 32/80\n",
      " - 4s - loss: 0.0907 - acc: 0.9710 - val_loss: 0.0956 - val_acc: 0.9681\n",
      "Epoch 33/80\n",
      " - 4s - loss: 0.0866 - acc: 0.9726 - val_loss: 0.0923 - val_acc: 0.9710\n",
      "Epoch 34/80\n",
      " - 4s - loss: 0.0845 - acc: 0.9734 - val_loss: 0.0923 - val_acc: 0.9686\n",
      "Epoch 35/80\n",
      " - 4s - loss: 0.0861 - acc: 0.9727 - val_loss: 0.0940 - val_acc: 0.9683\n",
      "Epoch 36/80\n",
      " - 4s - loss: 0.0826 - acc: 0.9746 - val_loss: 0.0904 - val_acc: 0.9707\n",
      "Epoch 37/80\n",
      " - 4s - loss: 0.0825 - acc: 0.9735 - val_loss: 0.0919 - val_acc: 0.9700\n",
      "Epoch 38/80\n",
      " - 4s - loss: 0.0842 - acc: 0.9733 - val_loss: 0.0905 - val_acc: 0.9690\n",
      "Epoch 39/80\n",
      " - 4s - loss: 0.0816 - acc: 0.9737 - val_loss: 0.0956 - val_acc: 0.9686\n",
      "Epoch 40/80\n",
      " - 4s - loss: 0.0810 - acc: 0.9747 - val_loss: 0.0866 - val_acc: 0.9712\n",
      "Epoch 41/80\n",
      " - 4s - loss: 0.0762 - acc: 0.9755 - val_loss: 0.0917 - val_acc: 0.9710\n",
      "Epoch 42/80\n",
      " - 4s - loss: 0.0780 - acc: 0.9753 - val_loss: 0.0850 - val_acc: 0.9714\n",
      "Epoch 43/80\n",
      " - 4s - loss: 0.0784 - acc: 0.9746 - val_loss: 0.0867 - val_acc: 0.9719\n",
      "Epoch 44/80\n",
      " - 4s - loss: 0.0747 - acc: 0.9761 - val_loss: 0.0844 - val_acc: 0.9726\n",
      "Epoch 45/80\n",
      " - 4s - loss: 0.0760 - acc: 0.9758 - val_loss: 0.0926 - val_acc: 0.9688\n",
      "Epoch 46/80\n",
      " - 4s - loss: 0.0755 - acc: 0.9762 - val_loss: 0.0842 - val_acc: 0.9733\n",
      "Epoch 47/80\n",
      " - 4s - loss: 0.0711 - acc: 0.9776 - val_loss: 0.0862 - val_acc: 0.9724\n",
      "Epoch 48/80\n",
      " - 4s - loss: 0.0720 - acc: 0.9770 - val_loss: 0.0807 - val_acc: 0.9743\n",
      "Epoch 49/80\n",
      " - 4s - loss: 0.0717 - acc: 0.9782 - val_loss: 0.0823 - val_acc: 0.9743\n",
      "Epoch 50/80\n",
      " - 4s - loss: 0.0713 - acc: 0.9774 - val_loss: 0.0873 - val_acc: 0.9714\n",
      "Epoch 51/80\n",
      " - 4s - loss: 0.0729 - acc: 0.9763 - val_loss: 0.0877 - val_acc: 0.9729\n",
      "Epoch 52/80\n",
      " - 4s - loss: 0.0702 - acc: 0.9774 - val_loss: 0.0810 - val_acc: 0.9752\n",
      "Epoch 53/80\n",
      " - 4s - loss: 0.0696 - acc: 0.9775 - val_loss: 0.0847 - val_acc: 0.9724\n",
      "Epoch 54/80\n",
      " - 4s - loss: 0.0665 - acc: 0.9790 - val_loss: 0.0864 - val_acc: 0.9729\n",
      "Epoch 55/80\n",
      " - 4s - loss: 0.0681 - acc: 0.9785 - val_loss: 0.0828 - val_acc: 0.9743\n",
      "Epoch 56/80\n",
      " - 4s - loss: 0.0692 - acc: 0.9769 - val_loss: 0.0798 - val_acc: 0.9748\n",
      "Epoch 57/80\n",
      " - 4s - loss: 0.0674 - acc: 0.9788 - val_loss: 0.0860 - val_acc: 0.9733\n",
      "Epoch 58/80\n",
      " - 4s - loss: 0.0689 - acc: 0.9777 - val_loss: 0.0790 - val_acc: 0.9740\n",
      "Epoch 59/80\n",
      " - 4s - loss: 0.0660 - acc: 0.9789 - val_loss: 0.0799 - val_acc: 0.9740\n",
      "Epoch 60/80\n",
      " - 4s - loss: 0.0680 - acc: 0.9787 - val_loss: 0.0772 - val_acc: 0.9745\n",
      "Epoch 61/80\n",
      " - 4s - loss: 0.0641 - acc: 0.9799 - val_loss: 0.0828 - val_acc: 0.9748\n",
      "Epoch 62/80\n",
      " - 4s - loss: 0.0665 - acc: 0.9784 - val_loss: 0.0794 - val_acc: 0.9740\n",
      "Epoch 63/80\n",
      " - 4s - loss: 0.0643 - acc: 0.9792 - val_loss: 0.0792 - val_acc: 0.9748\n",
      "Epoch 64/80\n",
      " - 4s - loss: 0.0633 - acc: 0.9797 - val_loss: 0.0805 - val_acc: 0.9752\n",
      "Epoch 65/80\n",
      " - 4s - loss: 0.0636 - acc: 0.9788 - val_loss: 0.0771 - val_acc: 0.9760\n",
      "Epoch 66/80\n",
      " - 4s - loss: 0.0616 - acc: 0.9804 - val_loss: 0.0834 - val_acc: 0.9745\n",
      "Epoch 67/80\n",
      " - 4s - loss: 0.0605 - acc: 0.9801 - val_loss: 0.0821 - val_acc: 0.9743\n",
      "Epoch 68/80\n",
      " - 4s - loss: 0.0623 - acc: 0.9795 - val_loss: 0.0814 - val_acc: 0.9762\n",
      "Epoch 69/80\n",
      " - 4s - loss: 0.0615 - acc: 0.9799 - val_loss: 0.0864 - val_acc: 0.9745\n",
      "Epoch 70/80\n",
      " - 4s - loss: 0.0611 - acc: 0.9806 - val_loss: 0.0776 - val_acc: 0.9760\n",
      "Epoch 71/80\n",
      " - 4s - loss: 0.0601 - acc: 0.9801 - val_loss: 0.0767 - val_acc: 0.9755\n",
      "Epoch 72/80\n",
      " - 4s - loss: 0.0596 - acc: 0.9805 - val_loss: 0.0818 - val_acc: 0.9743\n",
      "Epoch 73/80\n",
      " - 4s - loss: 0.0628 - acc: 0.9801 - val_loss: 0.0772 - val_acc: 0.9771\n",
      "Epoch 74/80\n",
      " - 4s - loss: 0.0599 - acc: 0.9804 - val_loss: 0.0825 - val_acc: 0.9743\n",
      "Epoch 75/80\n",
      " - 4s - loss: 0.0597 - acc: 0.9804 - val_loss: 0.0824 - val_acc: 0.9755\n",
      "Epoch 76/80\n",
      " - 4s - loss: 0.0608 - acc: 0.9809 - val_loss: 0.0807 - val_acc: 0.9743\n",
      "Epoch 77/80\n",
      " - 4s - loss: 0.0595 - acc: 0.9802 - val_loss: 0.0790 - val_acc: 0.9748\n",
      "Epoch 78/80\n",
      " - 4s - loss: 0.0566 - acc: 0.9819 - val_loss: 0.0821 - val_acc: 0.9733\n",
      "Epoch 79/80\n",
      " - 5s - loss: 0.0587 - acc: 0.9798 - val_loss: 0.0775 - val_acc: 0.9771\n",
      "Epoch 80/80\n",
      " - 4s - loss: 0.0599 - acc: 0.9798 - val_loss: 0.0732 - val_acc: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26c836399b0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BEST\n",
    "train = pd.read_csv('train.csv')\n",
    "labels = train.label.values.astype('int32')\n",
    "X_train = (train.drop(columns='label').values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "\n",
    "# convert list of labels to binary class matrix\n",
    "y_train = np_utils.to_categorical(labels) \n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',kernel_constraint=maxnorm(2)))\n",
    "model.add(Activation('softsign'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, kernel_initializer='he_uniform',kernel_constraint=maxnorm(1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softplus'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=100, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
