{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1st Kaggle competition : digit recognizer</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from time import time\n",
    "from tensorflow.python.keras.utils import np_utils, to_categorical\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.keras.constraints import maxnorm\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data vizualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data=(data.drop(columns='label')).values\n",
    "labeled_data_num=(data.label).values\n",
    "labeled_data=to_categorical(labeled_data_num)\n",
    "train_data0 = train_data.reshape(train_data.shape[0], 28, 28)\n",
    "plt.figure(figsize=(13,13))\n",
    "for i in range(5, 9):\n",
    "    plt.subplot(450 + (i+1))\n",
    "    plt.imshow(train_data0[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(labeled_data_num[i])\n",
    "    plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e18bef26d8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.label.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns='label'), data.label, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X=data.drop(columns='label')\n",
    "y=data.label\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [1, 3, 5, 6],\n",
    "              \"max_features\": [2, 3, 5, 9],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n",
    "-------\n",
    "GridSearchCV took 695.26 seconds for 18 candidate parameter settings.\n",
    "Model with rank: 1\n",
    "Mean validation score: 0.857 (std: 0.003)\n",
    "Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 9}\n",
    "\n",
    "Model with rank: 2\n",
    "Mean validation score: 0.853 (std: 0.005)\n",
    "Parameters: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 9}\n",
    "\n",
    "Model with rank: 3\n",
    "Mean validation score: 0.827 (std: 0.007)\n",
    "Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc  = RandomForestClassifier(n_estimators = 300,criterion= 'gini', max_depth= 5, max_features=9)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print('Accuracy of Random Forest model:', accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns='label'), data.label, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X=data.drop(columns='label')\n",
    "y=data.label\n",
    "\n",
    "xgboost = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"eta\": [0.01, 0.2],\n",
    "              \"max_depth\": [3,6,9]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xgboost, param_grid=param_grid, cv=10, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(objective='multi:softmax', num_class=10, \n",
    "        n_jobs=-1,booster=\"gbtree\",tree_method = \"hist\",\n",
    "        grow_policy = \"depthwise\")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "print('Accuracy of XGboost model:', accuracy_score(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning : neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and split data\n",
    "X_train = (data.drop(columns='label').values).astype('float32')\n",
    "#Preprocessing : converting labels into categorical\n",
    "y_train = np_utils.to_categorical(data.label.values.astype('int32'))\n",
    "#Preprocessing : normalization\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for epochs and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best batch size and epochs: 0.975667 using {'batch_size': 100, 'epochs': 100}\n",
      "0.965095 (0.003154) with: {'batch_size': 20, 'epochs': 20}\n",
      "0.973190 (0.000640) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.973167 (0.001537) with: {'batch_size': 20, 'epochs': 80}\n",
      "0.975643 (0.000707) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.968262 (0.000676) with: {'batch_size': 50, 'epochs': 20}\n",
      "0.972333 (0.000930) with: {'batch_size': 50, 'epochs': 50}\n",
      "0.973333 (0.000551) with: {'batch_size': 50, 'epochs': 80}\n",
      "0.973357 (0.001742) with: {'batch_size': 50, 'epochs': 100}\n",
      "0.964786 (0.000673) with: {'batch_size': 100, 'epochs': 20}\n",
      "0.972738 (0.001987) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.973381 (0.001190) with: {'batch_size': 100, 'epochs': 80}\n",
      "0.975667 (0.003279) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128, kernel_initializer='he_normal',kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [20, 50, 100]\n",
    "epochs = [20, 50, 80, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best batch size and epochs: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best optimizer: 0.978548 using {'optimizer': 'Adamax'}\n",
      "0.977619 (0.001758) with: {'optimizer': 'Adadelta'}\n",
      "0.978071 (0.001125) with: {'optimizer': 'Adam'}\n",
      "0.978548 (0.001050) with: {'optimizer': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for optimizer\n",
    "def create_model(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',\n",
    "                    kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128,kernel_initializer='he_normal',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['Adadelta', 'Adam', 'Adamax']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best optimizer: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 1: 0.976857 using {'activation': 'softplus'}\n",
      "0.934024 (0.004367) with: {'activation': 'softmax'}\n",
      "0.976857 (0.000955) with: {'activation': 'softplus'}\n",
      "0.975214 (0.001162) with: {'activation': 'softsign'}\n",
      "0.976548 (0.001639) with: {'activation': 'relu'}\n",
      "0.975857 (0.002469) with: {'activation': 'tanh'}\n",
      "0.975548 (0.000554) with: {'activation': 'sigmoid'}\n",
      "0.976381 (0.000834) with: {'activation': 'hard_sigmoid'}\n",
      "0.973595 (0.001410) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',\n",
    "                kernel_constraint=maxnorm(2), activation=activation))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128,kernel_initializer='lecun_uniform',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best activation 1: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 2: 0.978095 using {'activation': 'relu'}\n",
      "0.940571 (0.007508) with: {'activation': 'softmax'}\n",
      "0.975310 (0.001584) with: {'activation': 'softplus'}\n",
      "0.975643 (0.000254) with: {'activation': 'softsign'}\n",
      "0.978095 (0.001330) with: {'activation': 'relu'}\n",
      "0.976143 (0.000292) with: {'activation': 'tanh'}\n",
      "0.975071 (0.000202) with: {'activation': 'sigmoid'}\n",
      "0.974429 (0.001313) with: {'activation': 'hard_sigmoid'}\n",
      "0.976167 (0.000089) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',\n",
    "                kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128,kernel_initializer='he_normal',kernel_constraint=maxnorm(1),\n",
    "                    activation=activation))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best activation 2: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 3: 0.974524 using {'activation': 'softmax'}\n",
      "0.974524 (0.000854) with: {'activation': 'softmax'}\n",
      "0.973071 (0.003171) with: {'activation': 'softplus'}\n",
      "0.105929 (0.018055) with: {'activation': 'softsign'}\n",
      "0.098381 (0.001807) with: {'activation': 'relu'}\n",
      "0.094952 (0.003207) with: {'activation': 'tanh'}\n",
      "0.973595 (0.001664) with: {'activation': 'sigmoid'}\n",
      "0.098952 (0.002316) with: {'activation': 'hard_sigmoid'}\n",
      "0.151095 (0.073178) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',\n",
    "                kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128,kernel_initializer='lecun_uniform',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes,activation=activation))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best activation 3: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for init mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best init mode: 0.978381 using {'init_mode': 'he_uniform'}\n",
      "0.969810 (0.003075) with: {'init_mode': 'uniform'}\n",
      "0.977690 (0.001110) with: {'init_mode': 'lecun_uniform'}\n",
      "0.977262 (0.000761) with: {'init_mode': 'normal'}\n",
      "0.976286 (0.000802) with: {'init_mode': 'zero'}\n",
      "0.976548 (0.000379) with: {'init_mode': 'glorot_normal'}\n",
      "0.977690 (0.000943) with: {'init_mode': 'glorot_uniform'}\n",
      "0.977952 (0.000607) with: {'init_mode': 'he_normal'}\n",
      "0.978381 (0.000980) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(init_mode='uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer=init_mode,\n",
    "                kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128,kernel_initializer='he_normal',kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best init mode: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best init mode: 0.978190 using {'init_mode': 'he_normal'}\n",
      "0.973619 (0.001510) with: {'init_mode': 'uniform'}\n",
      "0.976738 (0.002451) with: {'init_mode': 'lecun_uniform'}\n",
      "0.977619 (0.001152) with: {'init_mode': 'normal'}\n",
      "0.111524 (0.001483) with: {'init_mode': 'zero'}\n",
      "0.976738 (0.000846) with: {'init_mode': 'glorot_normal'}\n",
      "0.977476 (0.000034) with: {'init_mode': 'glorot_uniform'}\n",
      "0.978190 (0.000650) with: {'init_mode': 'he_normal'}\n",
      "0.977405 (0.001635) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(init_mode='uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',\n",
    "                kernel_constraint=maxnorm(2)))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(128,kernel_initializer=init_mode,kernel_constraint=maxnorm(1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best init mode: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.5670 - acc: 0.8242 - val_loss: 0.2903 - val_acc: 0.9140\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3189 - acc: 0.9031 - val_loss: 0.2374 - val_acc: 0.9295\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2623 - acc: 0.9199 - val_loss: 0.2111 - val_acc: 0.9386\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2285 - acc: 0.9303 - val_loss: 0.1768 - val_acc: 0.9471\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2006 - acc: 0.9394 - val_loss: 0.1607 - val_acc: 0.9486\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1845 - acc: 0.9424 - val_loss: 0.1501 - val_acc: 0.9552\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1692 - acc: 0.9482 - val_loss: 0.1385 - val_acc: 0.9564\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1575 - acc: 0.9517 - val_loss: 0.1327 - val_acc: 0.9581\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1509 - acc: 0.9535 - val_loss: 0.1310 - val_acc: 0.9560\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1450 - acc: 0.9539 - val_loss: 0.1244 - val_acc: 0.9614\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1390 - acc: 0.9578 - val_loss: 0.1214 - val_acc: 0.9610\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1339 - acc: 0.9579 - val_loss: 0.1172 - val_acc: 0.9621\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1297 - acc: 0.9587 - val_loss: 0.1183 - val_acc: 0.9610\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1238 - acc: 0.9604 - val_loss: 0.1112 - val_acc: 0.9636\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1210 - acc: 0.9624 - val_loss: 0.1086 - val_acc: 0.9640\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.1187 - acc: 0.9630 - val_loss: 0.1153 - val_acc: 0.9621\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.1155 - acc: 0.9632 - val_loss: 0.1072 - val_acc: 0.9662\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1128 - acc: 0.9654 - val_loss: 0.1112 - val_acc: 0.9621\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.1102 - acc: 0.9656 - val_loss: 0.1065 - val_acc: 0.9671\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.1066 - acc: 0.9665 - val_loss: 0.0992 - val_acc: 0.9676\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1059 - acc: 0.9663 - val_loss: 0.1017 - val_acc: 0.9676\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.1030 - acc: 0.9675 - val_loss: 0.1002 - val_acc: 0.9683\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.1000 - acc: 0.9684 - val_loss: 0.1031 - val_acc: 0.9671\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1022 - acc: 0.9668 - val_loss: 0.0911 - val_acc: 0.9707\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.0967 - acc: 0.9697 - val_loss: 0.0946 - val_acc: 0.9690\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.0950 - acc: 0.9696 - val_loss: 0.0934 - val_acc: 0.9693\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.0932 - acc: 0.9701 - val_loss: 0.0912 - val_acc: 0.9705\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.0939 - acc: 0.9700 - val_loss: 0.0991 - val_acc: 0.9683\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.0938 - acc: 0.9697 - val_loss: 0.0910 - val_acc: 0.9705\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.0921 - acc: 0.9699 - val_loss: 0.1052 - val_acc: 0.9662\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.0940 - acc: 0.9697 - val_loss: 0.1016 - val_acc: 0.9676\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.0881 - acc: 0.9720 - val_loss: 0.0872 - val_acc: 0.9721\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.0866 - acc: 0.9719 - val_loss: 0.0844 - val_acc: 0.9755\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.0859 - acc: 0.9723 - val_loss: 0.0893 - val_acc: 0.9717\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.0858 - acc: 0.9718 - val_loss: 0.0971 - val_acc: 0.9695\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.0847 - acc: 0.9734 - val_loss: 0.0890 - val_acc: 0.9726\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.0824 - acc: 0.9735 - val_loss: 0.0886 - val_acc: 0.9719\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.0836 - acc: 0.9728 - val_loss: 0.0872 - val_acc: 0.9719\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.0814 - acc: 0.9730 - val_loss: 0.0871 - val_acc: 0.9721\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.0805 - acc: 0.9737 - val_loss: 0.0809 - val_acc: 0.9738\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.0789 - acc: 0.9738 - val_loss: 0.0852 - val_acc: 0.9726\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.0807 - acc: 0.9731 - val_loss: 0.0856 - val_acc: 0.9740\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.0798 - acc: 0.9739 - val_loss: 0.0869 - val_acc: 0.9719\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.0777 - acc: 0.9748 - val_loss: 0.0823 - val_acc: 0.9726\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.0782 - acc: 0.9755 - val_loss: 0.0832 - val_acc: 0.9738\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.0803 - acc: 0.9743 - val_loss: 0.0812 - val_acc: 0.9738\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.0755 - acc: 0.9747 - val_loss: 0.0859 - val_acc: 0.9736\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.0766 - acc: 0.9747 - val_loss: 0.0785 - val_acc: 0.9760\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.0750 - acc: 0.9755 - val_loss: 0.0943 - val_acc: 0.9683\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.0742 - acc: 0.9752 - val_loss: 0.0870 - val_acc: 0.9717\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.0748 - acc: 0.9761 - val_loss: 0.0855 - val_acc: 0.9729\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.0722 - acc: 0.9768 - val_loss: 0.0853 - val_acc: 0.9719\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.0734 - acc: 0.9755 - val_loss: 0.0868 - val_acc: 0.9724\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.0714 - acc: 0.9769 - val_loss: 0.0840 - val_acc: 0.9740\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.0757 - acc: 0.9758 - val_loss: 0.0806 - val_acc: 0.9738\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.0723 - acc: 0.9765 - val_loss: 0.0869 - val_acc: 0.9721\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.0712 - acc: 0.9763 - val_loss: 0.0807 - val_acc: 0.9726\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.0706 - acc: 0.9764 - val_loss: 0.0786 - val_acc: 0.9762\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.0721 - acc: 0.9766 - val_loss: 0.0805 - val_acc: 0.9717\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.0721 - acc: 0.9766 - val_loss: 0.0828 - val_acc: 0.9733\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.0705 - acc: 0.9768 - val_loss: 0.0837 - val_acc: 0.9745\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.0708 - acc: 0.9770 - val_loss: 0.0698 - val_acc: 0.9793\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.0717 - acc: 0.9767 - val_loss: 0.0810 - val_acc: 0.9736\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.0683 - acc: 0.9774 - val_loss: 0.0786 - val_acc: 0.9748\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.0694 - acc: 0.9764 - val_loss: 0.0767 - val_acc: 0.9767\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.0694 - acc: 0.9771 - val_loss: 0.0835 - val_acc: 0.9731\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.0682 - acc: 0.9783 - val_loss: 0.0760 - val_acc: 0.9760\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.0678 - acc: 0.9774 - val_loss: 0.0739 - val_acc: 0.9776\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.0658 - acc: 0.9788 - val_loss: 0.0808 - val_acc: 0.9738\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.0690 - acc: 0.9774 - val_loss: 0.0858 - val_acc: 0.9726\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.0686 - acc: 0.9773 - val_loss: 0.0827 - val_acc: 0.9745\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.0659 - acc: 0.9778 - val_loss: 0.0805 - val_acc: 0.9740\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.0659 - acc: 0.9784 - val_loss: 0.0765 - val_acc: 0.9769\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.0657 - acc: 0.9786 - val_loss: 0.0894 - val_acc: 0.9717\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.0629 - acc: 0.9789 - val_loss: 0.0759 - val_acc: 0.9745\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.0659 - acc: 0.9779 - val_loss: 0.0791 - val_acc: 0.9767\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.0642 - acc: 0.9781 - val_loss: 0.0781 - val_acc: 0.9757\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0636 - acc: 0.9787 - val_loss: 0.0783 - val_acc: 0.9762\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0653 - acc: 0.9785 - val_loss: 0.0827 - val_acc: 0.9748\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0624 - acc: 0.9794 - val_loss: 0.0834 - val_acc: 0.9743\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.0627 - acc: 0.9794 - val_loss: 0.0793 - val_acc: 0.9752\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0635 - acc: 0.9789 - val_loss: 0.0780 - val_acc: 0.9757\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0642 - acc: 0.9787 - val_loss: 0.0749 - val_acc: 0.9788\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.0621 - acc: 0.9796 - val_loss: 0.0885 - val_acc: 0.9724\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.0641 - acc: 0.9787 - val_loss: 0.0773 - val_acc: 0.9776\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0612 - acc: 0.9804 - val_loss: 0.0764 - val_acc: 0.9774\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0623 - acc: 0.9788 - val_loss: 0.0826 - val_acc: 0.9733\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0621 - acc: 0.9795 - val_loss: 0.0822 - val_acc: 0.9731\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0626 - acc: 0.9790 - val_loss: 0.0766 - val_acc: 0.9762\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0632 - acc: 0.9787 - val_loss: 0.0746 - val_acc: 0.9771\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0611 - acc: 0.9791 - val_loss: 0.0784 - val_acc: 0.9755\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0632 - acc: 0.9796 - val_loss: 0.0822 - val_acc: 0.9743\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0596 - acc: 0.9806 - val_loss: 0.0733 - val_acc: 0.9764\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0615 - acc: 0.9790 - val_loss: 0.0714 - val_acc: 0.9767\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0593 - acc: 0.9803 - val_loss: 0.0742 - val_acc: 0.9760\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0585 - acc: 0.9808 - val_loss: 0.0845 - val_acc: 0.9736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 3s - loss: 0.0613 - acc: 0.9799 - val_loss: 0.0795 - val_acc: 0.9743\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0600 - acc: 0.9796 - val_loss: 0.0755 - val_acc: 0.9764\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0613 - acc: 0.9795 - val_loss: 0.0744 - val_acc: 0.9779\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.0609 - acc: 0.9799 - val_loss: 0.0748 - val_acc: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x241aba25668>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import and split data\n",
    "X_train = (data.drop(columns='label').values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "#Preprocessing : converting labels into categorical\n",
    "y_train = np_utils.to_categorical(data.label.values.astype('int32'))\n",
    "#Preprocessing : normalization\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "#Model\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim,kernel_initializer='he_uniform',kernel_constraint=maxnorm(1)))\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, kernel_initializer='he_normal',kernel_constraint=maxnorm(2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=100, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions...\n",
      "Predictions available\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating test predictions...\")\n",
    "preds = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "def write_preds(preds, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(fname, index=False, header=True)\n",
    "\n",
    "write_preds(preds, \"keras-nlp.csv\")\n",
    "print(\"Predictions available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ressources "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fchollet/simple-deep-mlp-with-keras/code\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "https://www.kaggle.com/shivamb/a-very-comprehensive-tutorial-nn-cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
