{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1st Kaggle competition : digit recognizer</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from time import time\n",
    "from tensorflow.python.keras.utils import np_utils, to_categorical\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c15077be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.label.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=(data.drop(columns='label')).values\n",
    "labeled_data_num=(data.label).values\n",
    "labeled_data=to_categorical(labeled_data_num)\n",
    "train_data0 = train_data.reshape(train_data.shape[0], 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\matplotlib\\text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,13))\n",
    "for i in range(5, 9):\n",
    "    plt.subplot(450 + (i+1))\n",
    "    plt.imshow(train_data0[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(labeled_data_num[i])\n",
    "    plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns='label'), data.label, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aline.debenath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 695.26 seconds for 18 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.857 (std: 0.003)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 9}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.853 (std: 0.005)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.827 (std: 0.007)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=data.drop(columns='label')\n",
    "y=data.label\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [1, 3, 5, 6],\n",
    "              \"max_features\": [2, 3, 5, 9],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639285714285715"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc  = RandomForestClassifier(n_estimators = 300,criterion= 'gini', max_depth= 5, max_features=9)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-1af8f57deeb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X=data.drop(columns='label')\n",
    "y=data.label\n",
    "\n",
    "xgboost = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"eta\": [0.01, 0.2],\n",
    "              \"max_depth\": [3,6,9]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xgboost, param_grid=param_grid, cv=10, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332142857142857"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBClassifier(objective='multi:softmax', num_class=10, \n",
    "        n_jobs=-1,booster=\"gbtree\",tree_method = \"hist\",\n",
    "        grow_policy = \"depthwise\")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "labels = train.label.values.astype('int32')\n",
    "X_train = (train.drop(columns='label').values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "y_test=(pd.read_csv('test.csv').values).astype('int32')\n",
    "# convert list of labels to binary class matrix\n",
    "y_train = np_utils.to_categorical(labels) \n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "X=(train.drop(columns='label').values).astype('float32')\n",
    "y= train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search all\n",
    "def create_model(activation='softsign',optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer=initi_mode,activation=activation))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(128,kernel_initializer=initi_mode1,activation=activation1))\n",
    "\tmodel.add(Dropout(0.1))\n",
    "\tmodel.add(Dense(nb_classes,activation=activation2))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "init_mode1 = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "activation1 = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "activation2 = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation,\n",
    "                  activation1=activation1,\n",
    "                  activation2=activation2,\n",
    "                  init_mode=init_mode,\n",
    "                  init_mode1=init_mode1,\n",
    "                  optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best parameters: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best batch size and epochs: 0.111524 using {'batch_size': 60, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.111524 (0.001483) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.111524 (0.001483) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.111524 (0.001483) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.111524 (0.001483) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.111524 (0.001483) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.111524 (0.001483) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.111524 (0.001483) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.111524 (0.001483) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.111524 (0.001483) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.111524 (0.001483) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.111524 (0.001483) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.111524 (0.001483) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for epochs and batch size\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform'))\n",
    "\tmodel.add(Activation('softsign'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128,kernel_initializer='zero'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes,kernel_initializer='lecun_uniform'))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model,verbose=0)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X,y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best batch size and epochs: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best optimizer: 0.976762 using {'optimizer': 'Adam'}\n",
      "0.966000 (0.002018) with: {'optimizer': 'SGD'}\n",
      "0.975786 (0.001814) with: {'optimizer': 'RMSprop'}\n",
      "0.973690 (0.001514) with: {'optimizer': 'Adagrad'}\n",
      "0.975762 (0.000948) with: {'optimizer': 'Adadelta'}\n",
      "0.976762 (0.000551) with: {'optimizer': 'Adam'}\n",
      "0.975452 (0.000676) with: {'optimizer': 'Adamax'}\n",
      "0.975571 (0.001080) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for optimizer\n",
    "def create_model(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best optimizer: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.802286 using {'init_mode': 'lecun_uniform'}\n",
      "0.098333 (0.001764) with: {'init_mode': 'uniform'}\n",
      "0.802286 (0.023856) with: {'init_mode': 'lecun_uniform'}\n",
      "0.125286 (0.026812) with: {'init_mode': 'normal'}\n",
      "0.111524 (0.001483) with: {'init_mode': 'zero'}\n",
      "0.778690 (0.030307) with: {'init_mode': 'glorot_normal'}\n",
      "0.667857 (0.022721) with: {'init_mode': 'glorot_uniform'}\n",
      "0.684786 (0.047568) with: {'init_mode': 'he_normal'}\n",
      "0.591452 (0.065356) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for init mode\n",
    "def create_model(init_mode='uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer=init_mode))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=100, verbose=0)\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best init mode 1: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best init mode 2: 0.944786 using {'init_mode': 'zero'}\n",
      "0.106571 (0.006448) with: {'init_mode': 'uniform'}\n",
      "0.878786 (0.007982) with: {'init_mode': 'lecun_uniform'}\n",
      "0.754738 (0.022658) with: {'init_mode': 'normal'}\n",
      "0.944786 (0.001017) with: {'init_mode': 'zero'}\n",
      "0.893714 (0.003459) with: {'init_mode': 'glorot_normal'}\n",
      "0.878690 (0.002276) with: {'init_mode': 'glorot_uniform'}\n",
      "0.870524 (0.012613) with: {'init_mode': 'he_normal'}\n",
      "0.863929 (0.000642) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "#Grid search for init mode\n",
    "def create_model(init_mode='uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128, kernel_initializer=init_mode))\n",
    "\tmodel.add(Activation('softsign'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes))\n",
    "\tmodel.add(Activation('softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=100, verbose=0)\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best init mode 2: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.970786 using {'activation': 'softsign'}\n",
      "0.858643 (0.041130) with: {'activation': 'softmax'}\n",
      "0.969595 (0.001881) with: {'activation': 'softplus'}\n",
      "0.970786 (0.001171) with: {'activation': 'softsign'}\n",
      "0.969357 (0.000210) with: {'activation': 'relu'}\n",
      "0.968190 (0.001908) with: {'activation': 'tanh'}\n",
      "0.968190 (0.001268) with: {'activation': 'sigmoid'}\n",
      "0.966619 (0.001635) with: {'activation': 'hard_sigmoid'}\n",
      "0.910643 (0.036111) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform',activation=activation))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128,activation='relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes,activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best activation 1: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.971429 using {'activation': 'relu'}\n",
      "0.952524 (0.003127) with: {'activation': 'softmax'}\n",
      "0.970476 (0.000962) with: {'activation': 'softplus'}\n",
      "0.967429 (0.001489) with: {'activation': 'softsign'}\n",
      "0.971429 (0.001149) with: {'activation': 'relu'}\n",
      "0.969452 (0.001137) with: {'activation': 'tanh'}\n",
      "0.967548 (0.002148) with: {'activation': 'sigmoid'}\n",
      "0.968976 (0.001285) with: {'activation': 'hard_sigmoid'}\n",
      "0.965071 (0.000964) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform',activation='softsign'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128,activation=activation))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes,activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best activation 2: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation 3: 0.971429 using {'activation': 'softplus'}\n",
      "0.971071 (0.000058) with: {'activation': 'softmax'}\n",
      "0.971429 (0.001444) with: {'activation': 'softplus'}\n",
      "0.143476 (0.065150) with: {'activation': 'softsign'}\n",
      "0.098381 (0.001807) with: {'activation': 'relu'}\n",
      "0.208786 (0.016779) with: {'activation': 'tanh'}\n",
      "0.970857 (0.000763) with: {'activation': 'sigmoid'}\n",
      "0.500405 (0.069335) with: {'activation': 'hard_sigmoid'}\n",
      "0.098381 (0.001807) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform',activation='softsign'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(128,activation='relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes,activation=activation))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best activation 3: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neurons: 0.972738 using {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.972286 (0.001318) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.971310 (0.001268) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.970667 (0.002029) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.970690 (0.000792) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.972738 (0.001464) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.971452 (0.001031) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.971905 (0.001378) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.970333 (0.000923) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.968881 (0.001045) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.969833 (0.001116) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.968976 (0.001887) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.969810 (0.001566) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.960024 (0.001058) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.959857 (0.002241) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.959119 (0.001709) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.959810 (0.001631) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.098381 (0.001807) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.098381 (0.001807) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.098381 (0.001807) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.098381 (0.001807) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='lecun_uniform',\n",
    "                    activation='softsign',kernel_constraint=maxnorm(weight_constraint)))\n",
    "\tmodel.add(Dropout(dropout_rate))\n",
    "\tmodel.add(Dense(128,activation='relu'))\n",
    "\tmodel.add(Dropout(0.15))\n",
    "\tmodel.add(Dense(nb_classes,activation='softplus'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\treturn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=100, verbose=0)\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 4, 5]\n",
    "dropout_rate = [0.1, 0.3,  0.5, 0.7, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best neurons: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/60\n",
      " - 16s - loss: 0.3481 - acc: 0.8942 - val_loss: 0.1850 - val_acc: 0.9421\n",
      "Epoch 2/60\n",
      " - 15s - loss: 0.1913 - acc: 0.9399 - val_loss: 0.1578 - val_acc: 0.9493\n",
      "Epoch 3/60\n",
      " - 15s - loss: 0.1599 - acc: 0.9485 - val_loss: 0.1510 - val_acc: 0.9524\n",
      "Epoch 4/60\n",
      " - 15s - loss: 0.1480 - acc: 0.9520 - val_loss: 0.1100 - val_acc: 0.9662\n",
      "Epoch 5/60\n",
      " - 15s - loss: 0.1362 - acc: 0.9568 - val_loss: 0.1591 - val_acc: 0.9502\n",
      "Epoch 6/60\n",
      " - 15s - loss: 0.1350 - acc: 0.9580 - val_loss: 0.1381 - val_acc: 0.9512\n",
      "Epoch 7/60\n",
      " - 15s - loss: 0.1285 - acc: 0.9593 - val_loss: 0.1371 - val_acc: 0.9595\n",
      "Epoch 8/60\n",
      " - 15s - loss: 0.1267 - acc: 0.9610 - val_loss: 0.1097 - val_acc: 0.9676\n",
      "Epoch 9/60\n",
      " - 16s - loss: 0.1249 - acc: 0.9601 - val_loss: 0.1314 - val_acc: 0.9600\n",
      "Epoch 10/60\n",
      " - 16s - loss: 0.1209 - acc: 0.9617 - val_loss: 0.1511 - val_acc: 0.9545\n",
      "Epoch 11/60\n",
      " - 15s - loss: 0.1269 - acc: 0.9602 - val_loss: 0.1325 - val_acc: 0.9569\n",
      "Epoch 12/60\n",
      " - 15s - loss: 0.1204 - acc: 0.9612 - val_loss: 0.1123 - val_acc: 0.9660\n",
      "Epoch 13/60\n",
      " - 15s - loss: 0.1235 - acc: 0.9610 - val_loss: 0.1174 - val_acc: 0.9629\n",
      "Epoch 14/60\n",
      " - 15s - loss: 0.1284 - acc: 0.9604 - val_loss: 0.1165 - val_acc: 0.9643\n",
      "Epoch 15/60\n",
      " - 15s - loss: 0.1183 - acc: 0.9633 - val_loss: 0.1264 - val_acc: 0.9605\n",
      "Epoch 16/60\n",
      " - 15s - loss: 0.1215 - acc: 0.9613 - val_loss: 0.1272 - val_acc: 0.9600\n",
      "Epoch 17/60\n",
      " - 15s - loss: 0.1170 - acc: 0.9627 - val_loss: 0.1157 - val_acc: 0.9636\n",
      "Epoch 18/60\n",
      " - 16s - loss: 0.1191 - acc: 0.9624 - val_loss: 0.1158 - val_acc: 0.9619\n",
      "Epoch 19/60\n",
      " - 15s - loss: 0.1184 - acc: 0.9629 - val_loss: 0.1211 - val_acc: 0.9607\n",
      "Epoch 20/60\n",
      " - 15s - loss: 0.1160 - acc: 0.9622 - val_loss: 0.1355 - val_acc: 0.9610\n",
      "Epoch 21/60\n",
      " - 15s - loss: 0.1204 - acc: 0.9615 - val_loss: 0.1303 - val_acc: 0.9626\n",
      "Epoch 22/60\n",
      " - 15s - loss: 0.1145 - acc: 0.9640 - val_loss: 0.1218 - val_acc: 0.9693\n",
      "Epoch 23/60\n",
      " - 15s - loss: 0.1167 - acc: 0.9626 - val_loss: 0.1349 - val_acc: 0.9629\n",
      "Epoch 24/60\n",
      " - 15s - loss: 0.1182 - acc: 0.9634 - val_loss: 0.1158 - val_acc: 0.9669\n",
      "Epoch 25/60\n",
      " - 15s - loss: 0.1146 - acc: 0.9632 - val_loss: 0.1342 - val_acc: 0.9650\n",
      "Epoch 26/60\n",
      " - 15s - loss: 0.1161 - acc: 0.9628 - val_loss: 0.1316 - val_acc: 0.9562\n",
      "Epoch 27/60\n",
      " - 15s - loss: 0.1151 - acc: 0.9638 - val_loss: 0.1176 - val_acc: 0.9650\n",
      "Epoch 28/60\n",
      " - 15s - loss: 0.1179 - acc: 0.9631 - val_loss: 0.1399 - val_acc: 0.9621\n",
      "Epoch 29/60\n",
      " - 15s - loss: 0.1174 - acc: 0.9624 - val_loss: 0.1125 - val_acc: 0.9669\n",
      "Epoch 30/60\n",
      " - 15s - loss: 0.1224 - acc: 0.9614 - val_loss: 0.1206 - val_acc: 0.9650\n",
      "Epoch 31/60\n",
      " - 15s - loss: 0.1143 - acc: 0.9640 - val_loss: 0.1106 - val_acc: 0.9705\n",
      "Epoch 32/60\n",
      " - 15s - loss: 0.1185 - acc: 0.9626 - val_loss: 0.1183 - val_acc: 0.9619\n",
      "Epoch 33/60\n",
      " - 15s - loss: 0.1136 - acc: 0.9640 - val_loss: 0.1214 - val_acc: 0.9660\n",
      "Epoch 34/60\n",
      " - 18s - loss: 0.1156 - acc: 0.9627 - val_loss: 0.1251 - val_acc: 0.9612\n",
      "Epoch 35/60\n",
      " - 17s - loss: 0.1189 - acc: 0.9631 - val_loss: 0.1039 - val_acc: 0.9688\n",
      "Epoch 36/60\n",
      " - 16s - loss: 0.1109 - acc: 0.9647 - val_loss: 0.1236 - val_acc: 0.9657\n",
      "Epoch 37/60\n",
      " - 15s - loss: 0.1145 - acc: 0.9635 - val_loss: 0.1167 - val_acc: 0.9660\n",
      "Epoch 38/60\n",
      " - 15s - loss: 0.1209 - acc: 0.9628 - val_loss: 0.1410 - val_acc: 0.9617\n",
      "Epoch 39/60\n",
      " - 15s - loss: 0.1165 - acc: 0.9636 - val_loss: 0.1050 - val_acc: 0.9693\n",
      "Epoch 40/60\n",
      " - 15s - loss: 0.1128 - acc: 0.9637 - val_loss: 0.1283 - val_acc: 0.9602\n",
      "Epoch 41/60\n",
      " - 15s - loss: 0.1146 - acc: 0.9649 - val_loss: 0.1167 - val_acc: 0.9674\n",
      "Epoch 42/60\n",
      " - 15s - loss: 0.1153 - acc: 0.9630 - val_loss: 0.1070 - val_acc: 0.9667\n",
      "Epoch 43/60\n",
      " - 15s - loss: 0.1193 - acc: 0.9634 - val_loss: 0.1159 - val_acc: 0.9621\n",
      "Epoch 44/60\n",
      " - 15s - loss: 0.1086 - acc: 0.9644 - val_loss: 0.1135 - val_acc: 0.9660\n",
      "Epoch 45/60\n",
      " - 15s - loss: 0.1156 - acc: 0.9633 - val_loss: 0.1246 - val_acc: 0.9624\n",
      "Epoch 46/60\n",
      " - 15s - loss: 0.1131 - acc: 0.9654 - val_loss: 0.1089 - val_acc: 0.9693\n",
      "Epoch 47/60\n",
      " - 15s - loss: 0.1181 - acc: 0.9627 - val_loss: 0.1180 - val_acc: 0.9652\n",
      "Epoch 48/60\n",
      " - 15s - loss: 0.1196 - acc: 0.9628 - val_loss: 0.1482 - val_acc: 0.9602\n",
      "Epoch 49/60\n",
      " - 15s - loss: 0.1194 - acc: 0.9631 - val_loss: 0.1447 - val_acc: 0.9588\n",
      "Epoch 50/60\n",
      " - 15s - loss: 0.1173 - acc: 0.9632 - val_loss: 0.1029 - val_acc: 0.9712\n",
      "Epoch 51/60\n",
      " - 15s - loss: 0.1132 - acc: 0.9648 - val_loss: 0.1605 - val_acc: 0.9562\n",
      "Epoch 52/60\n",
      " - 15s - loss: 0.1168 - acc: 0.9633 - val_loss: 0.1163 - val_acc: 0.9645\n",
      "Epoch 53/60\n",
      " - 15s - loss: 0.1136 - acc: 0.9639 - val_loss: 0.1271 - val_acc: 0.9619\n",
      "Epoch 54/60\n",
      " - 15s - loss: 0.1154 - acc: 0.9654 - val_loss: 0.1177 - val_acc: 0.9669\n",
      "Epoch 55/60\n",
      " - 15s - loss: 0.1148 - acc: 0.9638 - val_loss: 0.1051 - val_acc: 0.9700\n",
      "Epoch 56/60\n",
      " - 15s - loss: 0.1146 - acc: 0.9637 - val_loss: 0.1182 - val_acc: 0.9638\n",
      "Epoch 57/60\n",
      " - 16s - loss: 0.1145 - acc: 0.9641 - val_loss: 0.1214 - val_acc: 0.9660\n",
      "Epoch 58/60\n",
      " - 15s - loss: 0.1110 - acc: 0.9644 - val_loss: 0.1051 - val_acc: 0.9705\n",
      "Epoch 59/60\n",
      " - 16s - loss: 0.1138 - acc: 0.9651 - val_loss: 0.1032 - val_acc: 0.9707\n",
      "Epoch 60/60\n",
      " - 16s - loss: 0.1177 - acc: 0.9623 - val_loss: 0.1364 - val_acc: 0.9621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26c1d67ecf8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "labels = train.label.values.astype('int32')\n",
    "X_train = (train.drop(columns='label').values).astype('float32')\n",
    "X_test = (pd.read_csv('test.csv').values).astype('float32')\n",
    "\n",
    "# convert list of labels to binary class matrix\n",
    "y_train = np_utils.to_categorical(labels) \n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "\n",
    "# Here's a Deep Dumb MLP (DDMLP)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim,kernel_initializer='lecun_uniform',\n",
    "                kernel_constraint=maxnorm(2)))\n",
    "model.add(Activation('softsign'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softplus'))\n",
    "\n",
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=10, validation_split=0.1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
